{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_eG2sW1MQrV"
      },
      "source": [
        "# Assignment 2\n",
        "In this assignment, we will use a multi-layer perceptron network to build an image classifier for single digits. We will be using a public dataset for model development. The dataset we will be using is the MNIST digit dataset. The dataset contains 10 classes, where class `i` contains images of digit `i`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BOMls6CLGyUr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao4fnByOPKmT"
      },
      "source": [
        "####1. Create train_data and test_dataset objects using the MNIST digit dataset from torchvision.datasets module. (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9tLsPKsAPJOu"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_data = torchvision.datasets.MNIST(root='data', train=True, download=True, transform = transform)\n",
        "test_data = torchvision.datasets.MNIST(root='data', train=False, download=True, transform = transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXbRPNvvQ3s5"
      },
      "source": [
        "####2. Use the [random_split](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split) method to split the `train_data` into `train_dataset` (50000 images) and `validation_dataset` dataset (10000 images). (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "eMHxma1VXSDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b80a2d66-3250-4b15-e779-be18e58f046d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000 10000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Split the train dataset into train_dataset and validation_dataset\n",
        "train_dataset, validation_dataset = random_split(train_data, [50000, 10000])\n",
        "\n",
        "print(len(train_dataset), len(validation_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pej9bS2lfFkb"
      },
      "source": [
        "#### 3. Create dataloader objects for `train_dataset`, `validation_dataset`, and `test_dataset`. (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xd1zHUocfazi"
      },
      "outputs": [],
      "source": [
        "train_loader = data.DataLoader(train_dataset, batch_size= 64, shuffle=True)\n",
        "validation_loader = data.DataLoader(validation_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = data.DataLoader(test_data, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_R2J6A1ahUS"
      },
      "source": [
        "#### 4. Develop an MLP model for classifying MNIST images. The developed model should have four hidden layers of 256, 128, 64, and 32 neurons. Each hidden layer should be followed with a ReLU unit and a Dropout layer (p=0.2).  (15 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "WNsJAsisbdWm"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(28*28, 256, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(256, 128, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(128, 64, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(64, 32, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(32, 10, bias=True),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZnMNV1Id_n1"
      },
      "source": [
        "#### 5. Define the components needed for training a deep learning model. (10 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "0nT3ixTAQ4QQ"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01,momentum=0.9)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8uSNlodMVw-"
      },
      "source": [
        "#### 6. Write the training loop and train the model for 100 epochs. Print the training and validation accuracy and loss for each epoch. (35 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "TdT8Mh_NgzEK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95fb7ecf-e323-4c7f-bd4b-0edf74aaae17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Train Loss: 0.0190, Train Acc: 99.41%, Val Loss: 0.1017, Val Acc: 98.20%\n",
            "Epoch [2/100], Train Loss: 0.0012, Train Acc: 99.97%, Val Loss: 0.1021, Val Acc: 98.21%\n",
            "Epoch [3/100], Train Loss: 0.0003, Train Acc: 100.00%, Val Loss: 0.1029, Val Acc: 98.23%\n",
            "Epoch [4/100], Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.1086, Val Acc: 98.22%\n",
            "Epoch [5/100], Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.1083, Val Acc: 98.24%\n",
            "Epoch [6/100], Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.1076, Val Acc: 98.25%\n",
            "Epoch [7/100], Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.1089, Val Acc: 98.25%\n",
            "Epoch [8/100], Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.1100, Val Acc: 98.26%\n",
            "Epoch [9/100], Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.1111, Val Acc: 98.25%\n",
            "Epoch [10/100], Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.1120, Val Acc: 98.26%\n",
            "Epoch [11/100], Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 0.1129, Val Acc: 98.26%\n",
            "Epoch [12/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1137, Val Acc: 98.26%\n",
            "Epoch [13/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1145, Val Acc: 98.26%\n",
            "Epoch [14/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1152, Val Acc: 98.26%\n",
            "Epoch [15/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1159, Val Acc: 98.26%\n",
            "Epoch [16/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1167, Val Acc: 98.26%\n",
            "Epoch [17/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1171, Val Acc: 98.26%\n",
            "Epoch [18/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1177, Val Acc: 98.25%\n",
            "Epoch [19/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1183, Val Acc: 98.25%\n",
            "Epoch [20/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1188, Val Acc: 98.25%\n",
            "Epoch [21/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1193, Val Acc: 98.25%\n",
            "Epoch [22/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1198, Val Acc: 98.25%\n",
            "Epoch [23/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1203, Val Acc: 98.25%\n",
            "Epoch [24/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1207, Val Acc: 98.25%\n",
            "Epoch [25/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1212, Val Acc: 98.25%\n",
            "Epoch [26/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1216, Val Acc: 98.25%\n",
            "Epoch [27/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1220, Val Acc: 98.25%\n",
            "Epoch [28/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1224, Val Acc: 98.24%\n",
            "Epoch [29/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1247, Val Acc: 98.24%\n",
            "Epoch [30/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1232, Val Acc: 98.23%\n",
            "Epoch [31/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1235, Val Acc: 98.23%\n",
            "Epoch [32/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1267, Val Acc: 98.23%\n",
            "Epoch [33/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1242, Val Acc: 98.23%\n",
            "Epoch [34/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1280, Val Acc: 98.23%\n",
            "Epoch [35/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1282, Val Acc: 98.23%\n",
            "Epoch [36/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1252, Val Acc: 98.23%\n",
            "Epoch [37/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1255, Val Acc: 98.23%\n",
            "Epoch [38/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1258, Val Acc: 98.23%\n",
            "Epoch [39/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1262, Val Acc: 98.23%\n",
            "Epoch [40/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1264, Val Acc: 98.23%\n",
            "Epoch [41/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1267, Val Acc: 98.23%\n",
            "Epoch [42/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1269, Val Acc: 98.23%\n",
            "Epoch [43/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1272, Val Acc: 98.23%\n",
            "Epoch [44/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1275, Val Acc: 98.23%\n",
            "Epoch [45/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1277, Val Acc: 98.23%\n",
            "Epoch [46/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1280, Val Acc: 98.23%\n",
            "Epoch [47/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1302, Val Acc: 98.23%\n",
            "Epoch [48/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1285, Val Acc: 98.23%\n",
            "Epoch [49/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1291, Val Acc: 98.23%\n",
            "Epoch [50/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1289, Val Acc: 98.23%\n",
            "Epoch [51/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1292, Val Acc: 98.23%\n",
            "Epoch [52/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1294, Val Acc: 98.23%\n",
            "Epoch [53/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1296, Val Acc: 98.23%\n",
            "Epoch [54/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1298, Val Acc: 98.23%\n",
            "Epoch [55/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1314, Val Acc: 98.23%\n",
            "Epoch [56/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1306, Val Acc: 98.23%\n",
            "Epoch [57/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1304, Val Acc: 98.23%\n",
            "Epoch [58/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1306, Val Acc: 98.23%\n",
            "Epoch [59/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1309, Val Acc: 98.24%\n",
            "Epoch [60/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1345, Val Acc: 98.24%\n",
            "Epoch [61/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1316, Val Acc: 98.24%\n",
            "Epoch [62/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1314, Val Acc: 98.24%\n",
            "Epoch [63/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1316, Val Acc: 98.24%\n",
            "Epoch [64/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1318, Val Acc: 98.24%\n",
            "Epoch [65/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1361, Val Acc: 98.24%\n",
            "Epoch [66/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1327, Val Acc: 98.24%\n",
            "Epoch [67/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1323, Val Acc: 98.24%\n",
            "Epoch [68/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1325, Val Acc: 98.24%\n",
            "Epoch [69/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1327, Val Acc: 98.24%\n",
            "Epoch [70/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1328, Val Acc: 98.24%\n",
            "Epoch [71/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1330, Val Acc: 98.24%\n",
            "Epoch [72/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1332, Val Acc: 98.24%\n",
            "Epoch [73/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1333, Val Acc: 98.24%\n",
            "Epoch [74/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1335, Val Acc: 98.24%\n",
            "Epoch [75/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1348, Val Acc: 98.24%\n",
            "Epoch [76/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1365, Val Acc: 98.24%\n",
            "Epoch [77/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1340, Val Acc: 98.24%\n",
            "Epoch [78/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1341, Val Acc: 98.24%\n",
            "Epoch [79/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1343, Val Acc: 98.24%\n",
            "Epoch [80/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1345, Val Acc: 98.24%\n",
            "Epoch [81/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1346, Val Acc: 98.24%\n",
            "Epoch [82/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1347, Val Acc: 98.24%\n",
            "Epoch [83/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1349, Val Acc: 98.25%\n",
            "Epoch [84/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1364, Val Acc: 98.25%\n",
            "Epoch [85/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1352, Val Acc: 98.25%\n",
            "Epoch [86/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1358, Val Acc: 98.25%\n",
            "Epoch [87/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1354, Val Acc: 98.25%\n",
            "Epoch [88/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1372, Val Acc: 98.25%\n",
            "Epoch [89/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1379, Val Acc: 98.25%\n",
            "Epoch [90/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1358, Val Acc: 98.25%\n",
            "Epoch [91/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1415, Val Acc: 98.25%\n",
            "Epoch [92/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1361, Val Acc: 98.25%\n",
            "Epoch [93/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1380, Val Acc: 98.25%\n",
            "Epoch [94/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1374, Val Acc: 98.25%\n",
            "Epoch [95/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1365, Val Acc: 98.25%\n",
            "Epoch [96/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1366, Val Acc: 98.25%\n",
            "Epoch [97/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1368, Val Acc: 98.25%\n",
            "Epoch [98/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1369, Val Acc: 98.25%\n",
            "Epoch [99/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1370, Val Acc: 98.25%\n",
            "Epoch [100/100], Train Loss: 0.0000, Train Acc: 100.00%, Val Loss: 0.1371, Val Acc: 98.25%\n"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        # images = images.view(-1, 28*28)\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = train_loss / len(train_loader)\n",
        "    train_acc = 100 * correct / total\n",
        "\n",
        "    # Evaluate the model on validation dataset\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in validation_loader:\n",
        "            images = images.view(-1, 28*28)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss = val_loss / len(validation_loader)\n",
        "    val_acc = 100 * correct / total\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSDr2VB9Q0uA"
      },
      "source": [
        "####6. Test the model using the `test_dataset`, and report accuracy and loss. (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Njcfq-uZLriH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "818f1612-0792-4dc6-8d1b-400c2d4e1d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0936, Test Acc: 98.39%\n"
          ]
        }
      ],
      "source": [
        "def eval_model(model, test_loader, criterion): \n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for images, labels in test_loader:\n",
        "          # images = images.view(-1, 28*28)\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          test_loss += loss.item()\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  test_loss = test_loss / len(test_loader)\n",
        "  test_acc = 100 * correct / total\n",
        "\n",
        "  print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "eval_model(model, test_loader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx9bidatV5RT"
      },
      "source": [
        "#### 8. We would like to see how accurate the trained model is when applied to a set of images of digits with slight differences. The image of a digit in the MNIST dataset has a black background (0 value for pixel values). This might be like writing with white chalk on a blackboard. We make slight changes in the test datasets by applying a simple change `image = 1 - image`. In other words, we invert the pixel intensity values. The resulting images resemble a digit written with a black marker on a whiteboard. Test the model using the updated test_dataset, and report your observations regarding model performance. How would you change your pipeline if you redo this experiment? (15 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "tWL4gwwlTgOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4104b3c3-607c-4702-e9e2-1729b0c8e1c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 9.7539, Test Acc: 7.29%\n"
          ]
        }
      ],
      "source": [
        "inv_transform = transforms.Compose([transforms.ToTensor(), lambda image : 1-image])\n",
        "inv_test_data = torchvision.datasets.MNIST(root='data', train=False, download=True, transform = inv_transform)\n",
        "inv_test_dataloader = data.DataLoader(inv_test_data, batch_size = 64, shuffle=True)\n",
        "\n",
        "eval_model(model, inv_test_dataloader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy of the model on the inverted dataset is 7.29%, which is very low compared to the accuracy of the non inverted dataset."
      ],
      "metadata": {
        "id": "cqsJxiIklEy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import random\n",
        "new_transform = transforms.Compose([transforms.ToTensor(), lambda image : 1-image if random() < 0.5 else image])\n"
      ],
      "metadata": {
        "id": "jv44yUDKlPyM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After adding the new transformation, it would convert image randomly and would allow our model to be trained with these inverted images. This alllows our model to be trained on a wide variation of the mnist which would include random variations, hence making our model more accurate.\n"
      ],
      "metadata": {
        "id": "H-PiBfcMoUQC"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}